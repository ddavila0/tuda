{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow import parquet as pq\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parquet files\n",
    "dataset = pq.ParquetDataset(\"parquet/XRootD_06-23to29-2019\")\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = table.to_pandas()\n",
    "# Make some columns\n",
    "workflow_idFront = (df.app_info.str.split('/').str[-1]\n",
    "                               .str.split(':').str[:2]\n",
    "                               .str.join('_')\n",
    "                   ) # Front half of workflow_id\n",
    "workflow_idBack = (df.app_info.str.split('/').str[-1]\n",
    "                              .str.split(':').str[2:]\n",
    "                              .str.join('_')\n",
    "                  ) # Back half of workflow_id\n",
    "df[\"workflow_id\"] = workflow_idFront.map(str)+\":\"+workflow_idBack\n",
    "df[\"crab_id\"] = df.app_info.str.split('_').str[0]\n",
    "df[\"job_id\"] = df.crab_id.map(str)+\"/\"+df.workflow_id\n",
    "df[\"start_datetime\"] = pd.to_datetime(df.start_time, unit=\"ms\")\n",
    "\n",
    "file_size_lookup = df[df.operation == \"read\"].drop_duplicates([\"file_name\",\"file_size\"])[[\"file_name\", \"file_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['operation', 'app_info', 'file_name', 'file_size', 'server_host',\n",
       "       'client_host', 'client_domain', 'start_time', 'read_bytes',\n",
       "       'workflow_id', 'crab_id', 'job_id', 'start_datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "$J \\rightarrow$ a job\n",
    "<br/>\n",
    "$f \\rightarrow$ a file\n",
    "<br/><br/>\n",
    "$S(f) =$ size of file $f$\n",
    "<br/>\n",
    "$B(f) =$ bytes read from file $f$\n",
    "<br/>\n",
    "$N_J(f) =$ number of jobs that read from file $f$\n",
    "<br/>\n",
    "$\\mathcal{N}_f =$ number of _unique_ files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Set\n",
    "$$w = \\sum_{N_f} S(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Set: 152.96 TB\n"
     ]
    }
   ],
   "source": [
    "working_set = df[df.operation == \"read\"].drop_duplicates([\"file_name\", \"file_size\"]).file_size.sum()/1e12\n",
    "print(\"Working Set: {0:.2f} TB\".format(working_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Naive Reads\n",
    "$$r_{naive} = \\sum_i S(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Naive Reads: 771.07 TB\n"
     ]
    }
   ],
   "source": [
    "total_naive_reads = df.file_size.sum()/1e12\n",
    "print(\"Total Naive Reads: {0:.2f} TB\".format(total_naive_reads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Actual Reads\n",
    "$$r_{actual} = \\sum_i B(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actual Reads: 103.19 TB\n"
     ]
    }
   ],
   "source": [
    "total_actual_reads = df.read_bytes.sum()/1e12\n",
    "print(\"Total Actual Reads: {0:.2f} TB\".format(total_actual_reads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_file = df.groupby(\"file_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 1:\n",
    "$$\\mathcal{R}_1 = \\frac{\\sum_{\\mathcal{N_f}} N_{J}(f_i)}{\\mathcal{N}_f}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 1: 2.47\n"
     ]
    }
   ],
   "source": [
    "rmult_numer_1 = (df_by_file.app_info.nunique()).sum()\n",
    "rmult_denom_1 = df.file_name.nunique()\n",
    "\n",
    "rmult_1 = rmult_numer_1/rmult_denom_1\n",
    "print(\"Reuse Multplier 1: {0:.2f}\".format(rmult_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2\n",
    "$$\\mathcal{R}_2 = \\frac{\\sum_{\\mathcal{N_f}} N_{J}(f_i) \\times S(f_i)}{\\sum_{\\mathcal{N_f}} S(f_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 2: 2.58\n"
     ]
    }
   ],
   "source": [
    "rmult_numer_2 = (df_by_file.app_info.nunique()*df_by_file.file_size.apply(lambda group: group.unique()[0])).sum()\n",
    "rmult_denom_2 = np.sum(df[\"file_size\"].unique())\n",
    "\n",
    "rmult_2 = rmult_numer_2/rmult_denom_2\n",
    "print(\"Reuse Multplier 2: {0:.2f}\".format(rmult_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 3:\n",
    "$$\\mathcal{R}_3 = \\frac{\\sum_{\\mathcal{N_f}} N_{J}(f_i) \\times B(f_i)}{\\sum_{\\mathcal{N_f}} S(f_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 3: 1.53\n"
     ]
    }
   ],
   "source": [
    "rmult_numer_3 = (df_by_file.app_info.nunique()*df_by_file.read_bytes.sum()).sum()\n",
    "rmult_denom_3 = rmult_denom_2\n",
    "\n",
    "rmult_3 = rmult_numer_3/rmult_denom_3\n",
    "print(\"Reuse Multplier 3: {0:.2f}\".format(rmult_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-access",
   "language": "python",
   "name": "data-access"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
