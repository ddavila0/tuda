{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow import parquet as pq\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parquet files\n",
    "dataset = pq.ParquetDataset(\"parquet/XRootD_06-23to29-2019\")\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = table.to_pandas()\n",
    "# Make some columns\n",
    "workflow_idFront = (df.app_info.str.split('/').str[-1]\n",
    "                               .str.split(':').str[:2]\n",
    "                               .str.join('_')\n",
    "                   ) # Front half of workflow_id\n",
    "workflow_idBack = (df.app_info.str.split('/').str[-1]\n",
    "                              .str.split(':').str[2:]\n",
    "                              .str.join('_')\n",
    "                  ) # Back half of workflow_id\n",
    "df[\"workflow_id\"] = workflow_idFront.map(str)+\":\"+workflow_idBack\n",
    "df[\"crab_id\"] = df.app_info.str.split('_').str[0]\n",
    "df[\"job_id\"] = df.crab_id.map(str)+\"/\"+df.workflow_id\n",
    "df[\"start_datetime\"] = pd.to_datetime(df.start_time, unit=\"ms\")\n",
    "\n",
    "file_size_lookup = df[df.operation == \"read\"].drop_duplicates([\"file_name\",\"file_size\"])[[\"file_name\", \"file_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['operation', 'app_info', 'file_name', 'file_size', 'server_host',\n",
       "       'client_host', 'client_domain', 'start_time', 'read_bytes',\n",
       "       'workflow_id', 'crab_id', 'job_id', 'start_datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "$J \\rightarrow$ a job\n",
    "<br/>\n",
    "$f \\rightarrow$ a file\n",
    "<br/><br/>\n",
    "$S(f) =$ size of file $f$\n",
    "<br/>\n",
    "$B(f) =$ bytes read from file $f$\n",
    "<br/>\n",
    "$\\mathcal{N}_J(f) =$ number of unique jobs that read from file $f$\n",
    "<br/>\n",
    "$\\mathcal{N}_f =$ number of _unique_ files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Set\n",
    "$$w = \\sum_{N_f} S(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Set: 152.96 TB\n"
     ]
    }
   ],
   "source": [
    "working_set = df[df.operation == \"read\"].drop_duplicates([\"file_name\", \"file_size\"]).file_size.sum()/1e12\n",
    "print(\"Working Set: {0:.2f} TB\".format(working_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Naive Reads\n",
    "$$r_{naive} = \\sum_i S(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Naive Reads: 771.07 TB\n"
     ]
    }
   ],
   "source": [
    "total_naive_reads = df.file_size.sum()/1e12\n",
    "print(\"Total Naive Reads: {0:.2f} TB\".format(total_naive_reads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Actual Reads\n",
    "$$r_{actual} = \\sum_i B(f_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actual Reads: 103.19 TB\n"
     ]
    }
   ],
   "source": [
    "total_actual_reads = df.read_bytes.sum()/1e12\n",
    "print(\"Total Actual Reads: {0:.2f} TB\".format(total_actual_reads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Accesses per File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_file_accesses = (df.groupby(\"file_name\").app_info.nunique()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Unique Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_files = df.file_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_file = df.groupby(\"file_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 1:\n",
    "$$\\mathcal{R}_1 = \\frac{\\sum_{\\mathcal{N}_f} \\mathcal{N}_{J}(f_i)}{\\mathcal{N}_f}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 1: 2.47\n"
     ]
    }
   ],
   "source": [
    "rmult_1 = num_unique_file_accesses/num_unique_files\n",
    "print(\"Reuse Multplier 1: {0:.2f}\".format(rmult_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2\n",
    "$$\\mathcal{R}_2 = \\frac{r_{naive}}{w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 2: 5.04\n"
     ]
    }
   ],
   "source": [
    "rmult_2 = total_naive_reads/working_set\n",
    "print(\"Reuse Multplier 2: {0:.2f}\".format(rmult_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 3:\n",
    "$$\\mathcal{R}_3 = \\frac{r_{actual}}{w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse Multplier 3: 0.67\n"
     ]
    }
   ],
   "source": [
    "rmult_3 = total_actual_reads/working_set\n",
    "print(\"Reuse Multplier 3: {0:.2f}\".format(rmult_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-access",
   "language": "python",
   "name": "data-access"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
